# -*- coding: utf-8 -*-
"""SIC2022_DeepLearning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YgXQzoNl7X2wpiNvDMkCC6NgsrVHGgCE

#Primeras nociones de Deep-Learning y Redes Neuronales
"""

#import sys
#!{sys.executable} -m pip list #para saber que tengo instalado

#import sys
#!{sys.executable} -m pip install tensorflow

#import sys
#!{sys.executable} -m pip install keras

#import sys
#!{sys.executable} -m pip install nltk

'''import nltk

nltk.download('punkt')
nltk.download('wordnet')
nltk.download('universal_tagset')
nltk.download('spanish_grammars')
nltk.download('tagsets')

nltk.download('stopwords') # faltaaaaa
nltk.download('omw-1.4') #faltaaaa'''

# Conexión con Drive
#from google.colab import drive
#drive.mount('/content/drive')

def guardar_json(datos):
  import json
  archivo = open('intents.json', 'w+')
  json.dump(datos,archivo,indent=4)

#intents: grupos de conversaciones tipicas para nuestro objetivo
# patterns: posibles interacciones con el usuario

#dic={"intents:[[{"key":["vlores"]}],"dic2"]}


biblioteca={"intents":
            [
                {"tag":"saludos",
                 "patterns":["hola",
                             "buenos dias",
                             "buenas tardes",
                             "buenas noches",
                             "como estas",
                             "hay alguien ahi?",
                             "hey",
                             "saludos",
                             "que tal"                      
                             ],
                 "responses":["Hola soy AUTO-BOT , tu asesor de compras para tu futuro automóvil.\n ¿En qué puedo ayudarte? "
                             ],
                 "context":[""]
                 },
             
                {"tag":"compras",
                 "patterns":["consultar precios",
                             "comprar un auto",
                             "averiguar precio",
                             "busco un coche",
                             "informacion",
                             "necesito ayuda con",
                             "me puede colaborar",
                             "busco un auto",
                             "que carros tienen"                      
                             ],
                "responses":["Perfecto, ¿Quieres probar una busqueda directa o deseas una recomendacion basada en características?" 
                             ],
                 "context":[""]
                 },

                {"tag":"busqueda_directa",
                    "patterns":["busqueda directa",
                                "directo",
                                "de inmediato",
                                "busqueda inmediata",
                               ],
                    "responses":[ "¿Qué tipo de vehículo te gustaría. Por ejemplo: sedán, pickup, camioneta..."
                                ],
                    "context":[""]
                    },
             
                {"tag":"tipo",
                 "patterns":["sedan",
                             "pickup",
                             "camioneta",
                             "coupe",
                             "deportivos"                 
                             ],
                 "responses":["¿Alguna marca en particular?",
                              "¿Tiene alguna marca en mente?",
                              "¿Qué marca le gustaría?"
                             ],
                 "context":[""]
                 },
             
                {"tag":"marca",
                 "patterns":["nissan",
                             "honda",
                             "toyota",
                             "ford",
                             "isuzu",
                             "audi",
                             "bmw",
                             "subaru",
                             "mitsubihi",
                             "corvette"              
                             ],
                 "responses":["Listo, procederé a realizar la busqueda en bodéga del tipo y marca seleccionado",
                             ],
                 "context":[""]
                 },
                            
                {"tag":"recomendacion",
                    "patterns":["recomendación",
                                "recomiendes algo",
                                "necesito recomendación",
                                "que me recomiendas",
                                "necesito algunas específicaciones"
                                ],
                  "responses":["Buena elección. por favor siga estas instrucciones: \n Revisaremos las característica una a una. Por ejemplo, año del auto: 2020 . Si necesitas ayuda con algún concepto, escribe la palabra asistencia."
                                ],
                    "context":[""]
                    },

                {"tag":"anho_del_auto",
                    "patterns":["año",
                                "año:",
                                "del año"
                               ],
                    "responses":[ "¿Con cuantos caballos de fuerza?"
                                ],
                    "context":[""]
                    },
             
                {"tag":"caballos_de_fuerza",
                    "patterns":["120 caballos de fuerza",
                                "caballos de fuerza:",
                                "potencia de:"
                               ],
                    "responses":[ "¿Qué precio tiene en mente?"
                                ],
                    "context":[""]
                    },  
                {"tag":"precio_esperado",
                    "patterns":["12 000 dólares",
                                "precio: 30000",
                                "costo: 25000"
                               ],
                    "responses":[ "¿Cuál quiere que sea el rendimiento de combustible?"
                                ],
                    "context":[""]
                    },
             
                {"tag":"consumo_combustible",
                    "patterns":["cosumo:",
                                "que sea económico",
                                "50 kilómetros por galón"
                               ],
                    "responses":[ "¿Cuál quiere que sea el tipo de combustible? \n Gasolina, Diesel o Eléctrico."
                                ],
                    "context":[""]
                    },
                {"tag":"tipo_de_combustible",
                    "patterns":["combustible:",
                                "gasolina",
                                "diesel",
                                "eléctrico"
                               ],
                    "responses":[ "¿Cuántas plazas (asientos) aproximadamente necesita?"
                                ],
                    "context":[""]
                    },
                {"tag":"número_de_asientos",
                    "patterns":["asientos:",
                                "plazas:",
                                "espacioso",
                                "2 asientos"
                               ],
                    "responses":[ "¿Transmisión manual o automática?."
                                ],
                    "context":[""]
                    },
                {"tag":"tipo_de_transmisión",
                    "patterns":["transmisión manual",
                                "transmisión automática",
                                "manual",
                                "automática"
                               ],
                    "responses":[ "Listo. Ahora realizaré una estimación del vehículo disponible que mejor se ajusta a tus necesidades.\n Escribe 'recomendar ahora' para continuar."
                                ],
                    "context":[""]
                    },

                {"tag":"recomendar_ahora",
                 "patterns":["recomendar ahora"
                            ],
                 "responses":["Revisando características en bodega"
                             ],
                 "context":[""]
                 },
                

                {"tag":"asistencia",
                 "patterns":["asistencia"
                            ],
                 "responses":["¿Para cuál concepto necesita ayuda?\n Año del auto. Potencia en caballos de fuerza. Precio esperado. Consumo de combustible. Tipo de combustible. Número de asientos. Tipo de transmisión"
                             ],
                 "context":[""]
                 },
                
                {"tag":"despedidas",
                 "patterns":["chao",
                             "adios",
                             "hasta luego",
                             "nos vemos",
                             "bye",
                             "hasta pronto",
                             "hasta la proxima"
                             ],
                 "responses":["hasta luego, tenga un buen dia"
                             ],
                 "context":[""]
                 },
             
                {"tag":"agradecimientos",
                 "patterns":["gracias",
                             "muchas gracias",
                             "mil gracias",
                             "muy amable",
                             "se lo agradezco",
                             "fue de ayuda",
                             "gracias por la ayuda",
                             "muy agradecido",
                             "gracias por su tiempo",
                             "ty"
                            ],
                 "responses":["de nada",
                              "feliz por ayudarlo",
                              "gracias a usted",
                              "estamos para servirle",
                              "fue un placer"
                             ],
                 "context":[""]
                },
                {"tag":"norespuesta",
                 "patterns":[""],
                 "responses":["no se detecto una respuesta",
                             ],
                 "context":[""]                    
                }
            ] 
        }
guardar_json(biblioteca)

import json
import pickle
import numpy as np
import nltk
import keras
from nltk.stem import WordNetLemmatizer
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, Flatten, Dense,Dropout
from tensorflow.keras.optimizers import SGD

# Stemmer=LancasterStemmer() #opcional esp
lemmatizer=WordNetLemmatizer() 
# La lematización es el proceso de agrupar las diferentes formas flexionadas de una 
# palabra para que puedan ser analizadas como un único elemento
    
# ejemplo de lematizacion: https://es.wikipedia.org/wiki/Lematización
# lema -> palabra completa  : categoria
# casa -> casas             : plurales
# decir -> diré,dijeramos    :tiempos verbales


ignore_words=["?","¿","!","¡"]
data_file= open('intents.json').read() # Cargar el archivo en formato json
intents = json.loads(data_file) # Convertir el archivo json a diccionario
intents

words=[]
classes=[]
documents=[]

for intent in intents["intents"]: # Lista de interacciones
    for pattern in intent["patterns"]: # Lista de patrones
        
        
        # Tokenizar cada palabra
        w = nltk.word_tokenize(pattern) 
        '''Palabras tokenizadas'''
        # Separamos las oraciones palabra por palabra y guardamos cada palabra como token en la lista words
        words.extend(w)
        
        # Agrego un array de documentos. Corresponde a la frase y su respectiva clase
        documents.append((w,intent["tag"]))
        
        # Añadimos las clases asignadas a nuestra lista de clases
        if intent["tag"] not in classes:
            classes.append(intent["tag"])
            
print(words)

print("\n ####################################################################################################### \n")

print(documents)

print("\n ####################################################################################################### \n")

print(classes)

from nltk.stem import SnowballStemmer
stemmer = SnowballStemmer('spanish')

# ejemplo de lematizacion: https://es.wikipedia.org/wiki/Lematización
# lema -> palabra completa  : categoria
# casa -> casas             : plurales
# decir -> diré,dijeramos    :tiempos verbales

#La lematización es el proceso de agrupar las diferentes formas flexionadas de una 
                                #palabra para que puedan ser analizadas como un único elemento


#base de datos, verdad absoluta de las palabras -> REFERENCIA
words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]

print("Esta lista 'words' serán las palabras LEMATIZADAS de REFERENCIA")
print(words)


pickle.dump(words,open("words.pkl","wb"))
pickle.dump(classes,open("classes.pkl","wb"))
print(words)
print(classes)

"""#NLTK - Métodos

https://www.nltk.org/book_1ed/ch03.html

**Method Functionality**

`s.find(t)` = index of first instance of string t inside s (-1 if not found)

`s.rfind(t)` = index of last instance of string t inside s (-1 if not found)

`s.index(t)` = like s.find(t) except it raises ValueError if not found

`s.rindex(t)` = like s.rfind(t) except it raises ValueError if not found

`s.join(text)` = combine the words of the text into a string using s as the glue

`s.split(t)` = split s into a list wherever a t is found (whitespace by default)

`s.splitlines()` = split s into a list of strings, one per line

`s.lower()` = a lowercased version of the string s

`s.upper()` = an uppercased version of the string s

`s.title()` = a titlecased version of the string s

`s.strip()` = a copy of s without leading or trailing whitespace

`s.replace(t, u)` = replace instances of t with u inside s

---
Ahora, crearemos los datos de entrenamiento en los que proporcionaremos la entrada y la salida. Nuestra entrada será el patrón y la salida será la clase a la que pertenece nuestro patrón de entrada. Pero la computadora no entiende el texto, así que convertiremos el texto en números.
"""

# Preparacion para la formacion de nuestra red neuronal 
# En esta primera parte de nuestra red neuronal estamos haciendo un clasificador, words en tags

training=[]
output_empty=[0]*len(classes) # Creamos una matriz del numero de patterns con valor inicial 0

for doc in documents: # En doc esta la raw_data -> datos sin procesar
    
    # Bag of words
    bag=[]
    # Lista de tokens
    pattern_words = doc[0] # doc[0] es la lista de palabras
    # Lematizacion del token
    #pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words  if word not in ignore_words ]
    pattern_words= [stemmer.stem(word.lower()) for word in pattern_words  if word not in ignore_words ]
    # Si la palabra coincide introduzco 1, en caso contrario 0
    for palabra in words:
        bag.append(1) if palabra in pattern_words else bag.append(0) 
    
    output_row = list(output_empty)
    output_row[classes.index(doc[1])] = 1 #doc en la posicion 1 es el pattern
    
    training.append([bag,output_row])
    #print(output_row)

training = np.array(training,dtype=object)

print(len(training[0][0]))
print(training)

"""Estamos ENCRIPTANDO palabras a listas de 1 y 0

Convierte palabras en "booleano"(lista de 1 y 0) y les asigna una categoria.

Para asignar la categoria busca si esta en la lista de referencia.

Como son las categorias:
   ```
[1,0,0,0]=saludos
[0,1,0,0]=despedidas
[0,0,1,0]=agradecimientos
[0,0,0,1]=norespuesta
```


    
Forma pares:    

hola   :```[1, 0, 0, 0, 0, 0, ... [1,0,0] -> 10000``` : saludo

buenos :```[0, 1, 1, 0, 0, 0, ... [1,0,0] -> 01100``` : saludo
         
Estos pares son la data que vamos a mandar a la IA para poder crear el modelo:
 
      52                        4
 data=entradas             target=salidas

c1,c2,c3,c4,c5,c6...s1,s2,s3,s4

1  0  0  0  0  0    1  0  0   0  -> saludo    
"""

# En la clase anterior habiamos creado el training, ahora separamos
# Crear los conjuntos de entrenamiento  
# y prueba, x_test, x_train (entradas) , y_test , y_train (salidas)
        
# x_train= training[0] asi seria en listas     
x_train= list(training[:,0]) 
#asi porque estamos en formato numpy.array ||| training[inicio:fin,index]
y_train= list(training[:,1])

# Creacion del modelo

model = Sequential()
#https://keras.io/guides/sequential_model/
#https://www.youtube.com/watch?v=1M0x9k-rMDM

# Añadimos capas a la red
model.add(Dense(128, input_shape=(len(x_train[0]),), activation='relu')) 
#añadimos 1 capa: entrada de datos
model.add(Dropout(0.5))
model.add(Dense(64,activation='relu')) 
#capa oculta -> aprendizaje
model.add(Dropout(0.5))
model.add(Dense(len(y_train[0]),activation='softmax')) 
# capa de salida toma de desiciones

#El (DROPOUT) es una técnica en la que se ignoran neuronas seleccionadas al azar 
#durante el entrenamiento. Se "descartan" aleatoriamente. 
#Esto significa que su contribución a la activación de las neuronas descendentes 
#se elimina temporalmente en el paso hacia delante, y cualquier actualización de
#peso no se aplica a la neurona en el paso hacia atrás.


# SGD es un optimizador estocástico de descenso gradiente. 
# Incluye soporte para momentum, decaimiento de la tasa de aprendizaje y momentum Nesterov.

# SGD optimiza los parametros


sgd=SGD(lr=0.01,decay=1e-6,momentum=0.9,nesterov=True) 

model.compile(loss="categorical_crossentropy",optimizer=sgd,metrics=["accuracy"])

#le mando los datos de train para que entrene y aprenda
#fit ajusta los datos para crear un modelo (Sequential de 3 capas) que pueda predecir los datos

hist=model.fit(np.array(x_train),np.array(y_train),epochs=300,batch_size=5,verbose=1)
model.save("chatbot_model.h5",hist)
print("modelo creado")

# en deep learning el sistema aprende cada epoch , en el epoch=1 NO SABE NADA
# en el epoch 267, ya es brillante!

# preprocesamiento de la entrada del usuario!!

#todo lo que vaya con sentence es lo que ingreso el usuario

# en los siguientes 2 metodos  voy a convertir las palabras 
# que ingresa el usuario al formato
# de entrenamiento que usamos anteriormente, osea, 
# convertir las palabras en una lista de 1 y 0 
# en un array donde palabra,tag -> [1,0,0,1,1],[1,0,0,0]

def clean_up_sentence(sentence):
    # tokenizar la oracion
    sentence_words=nltk.word_tokenize(sentence) # tokenizamos
    sentence_words=[stemmer.stem(word.lower()) for word in sentence_words] 
    #lematizamos
    return sentence_words


def bow (sentence,words,show_details=True): 
  #lazo entre lo que ingreso el usuario tokenizado y la referencia 
    sentence_words=clean_up_sentence(sentence)
    
    bag=[0]*len(words)
    
    for i in sentence_words:
        for j,w in enumerate(words):
            if w==i: # asigna 1 si la palabra actual está en la posición del vocabulario 
                bag[j]=1
                if show_details:
                    print("encontrado en la bolsa: ",w)
    return (np.array(bag))

# ahora si utilizo el modelo para predecir que tipo de palabra es


def predict_class(sentence,model):
    # filtrar las predicciones  por debajo del umbral
    p = bow(sentence,words,show_details=False) # retorno del bag
    res = model.predict(np.array([p]))[0] # res es la eficacia, o probabilidad de que la palabra sea de algun tipo
    #model.predict me retorna el % eficacia  , ejm 60% saludo
    
    ERROR_THRESHOLD=0.25 #UMBRAL
    
    
    # a results le llega  [1,0,0,0]
    results= [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD] 
    # si la probabilidad es > 25% determinela como resultado correcto
    
    #r[0]= tag
    #r[1]= probabilidad
    
    #ordenar por peso de la probabilidad
    results.sort(key=lambda x: x[1], reverse=True)  
    #ordena de mayor a menor la probabilidad de que el resultado sea acertado
    return_list = []    
    for r in results:   
        return_list.append({"intent": classes[r[0]], "probability": str(r[1])})   
    return return_list

import random

def get_response(ints,intents_json): 
  # obtiene una respuesta aleatoria segun el ints correspondiente a lo que ingreso el usuario
    tag= ints[0]["intent"]
    print("TAG DEL USUARIO", tag)
    # obtenemos cual era el tag  segun lo que ingreso el usuario ints[0]
    list_of_intents=intents_json["intents"]
    # sacamos la lista de intents de referencia
    
    for i  in list_of_intents: 
        if (i["tag"]==tag): 
          #miramos donde coincide el tag del sentence con la referencia
            result= random.choice(i["responses"]) 
            # random.choice, toma un elemento aleatorio de la lista
            break
    return result
    
# este es el metodo principal, aqui nace todo
def chatbot_response(text): 
    ints=predict_class(text,model)
    print("INTENTS DEL USUARIO: ",ints)
    #ints es el intents que creamos a apartir de lo que ingreso el usuario
    res=get_response(ints,intents)
    # intents es el json de referencia
    return res
    
    
######################## SOLO PARA PROBARLO EN CONSOLA ##########################
# "main"
texto_us="" # lo que ingresa el usuario
print(" bienvenido, para salir  escriba salir \n")

while texto_us!="salir":
    texto_us=input()
    res=chatbot_response(texto_us)
    print(res)
